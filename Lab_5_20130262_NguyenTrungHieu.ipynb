{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenTrungHieu-20130262/20130262_NguyenTrungHieu_ML2023/blob/main/Lab_5_20130262_NguyenTrungHieu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bdbac99-82f2-4172-e38c-ad6afc1769a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Code Python\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Code Python'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code#1.1\n",
        "cancer = datasets.load_breast_cancer()\n",
        "model = svm.SVC(kernel ='linear')\n",
        "x_train = cancer.data\n",
        "y_train = cancer.target\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_train)\n",
        "print(confusion_matrix(y_train, y_pred))\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "#1.2\n",
        "lr = LogisticRegression(random_state = 0)\n",
        "lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(x_train)\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "tree_pred = tree.predict(x_train)\n",
        "\n",
        "\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(x_train, y_train)\n",
        "kNN_pred = kNN.predict(x_train)\n",
        "\n",
        "\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_train, y_pred), 2), \n",
        "           round(precision_score(y_train, y_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, y_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, y_pred,average='macro'), 2)])\n",
        "t.add_row([\"Logicstic\", round(accuracy_score(y_train, lr_pred), 2), \n",
        "           round(precision_score(y_train, lr_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, lr_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, lr_pred,average='macro'), 2)])\n",
        "t.add_row([\"Decision Tree\", round(accuracy_score(y_train, tree_pred), 2), \n",
        "           round(precision_score(y_train, tree_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, tree_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, tree_pred,average='macro'), 2)])\n",
        "t.add_row([\"kNN\", round(accuracy_score(y_train, kNN_pred), 2), \n",
        "           round(precision_score(y_train, kNN_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, kNN_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, kNN_pred,average='macro'), 2)])\n",
        "print(t)\n",
        "     \n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e23819-47a5-49cf-963b-e7fdf06ef145"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[201  11]\n",
            " [  8 349]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       212\n",
            "           1       0.97      0.98      0.97       357\n",
            "\n",
            "    accuracy                           0.97       569\n",
            "   macro avg       0.97      0.96      0.96       569\n",
            "weighted avg       0.97      0.97      0.97       569\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.97   |    0.97   |  0.96  | 0.96 |\n",
            "|   Logicstic   |   0.95   |    0.95   |  0.94  | 0.94 |\n",
            "| Decision Tree |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "|      kNN      |   0.95   |    0.95   |  0.94  | 0.94 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#2.1\n",
        "iris = datasets.load_iris()\n",
        "model = svm.SVC(kernel ='linear')\n",
        "x_train = cancer.data\n",
        "y_train = cancer.target\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_train)\n",
        "\n",
        "#2.2\n",
        "\n",
        "poly = svm.SVC(kernel='poly', degree=5)\n",
        "poly.fit(x_train, y_train)\n",
        "\n",
        "sigmoid = svm.SVC(kernel='sigmoid')\n",
        "sigmoid.fit(x_train, y_train)\n",
        "\n",
        "rbf = svm.SVC(kernel='rbf')\n",
        "rbf.fit(x_train, y_train)\n",
        "\n",
        "poly_pred =poly.predict(x_train)\n",
        "sigmoid_pred = sigmoid.predict(x_train)\n",
        "rbf_pred = rbf.predict(x_train)\n",
        "\n",
        "\n",
        "t = PrettyTable([\"Kernel\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"Linear\", round(accuracy_score(y_train, y_pred), 2), \n",
        "           round(precision_score(y_train, y_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, y_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, y_pred,average='macro'), 2)])\n",
        "t.add_row([\"Poly\", round(accuracy_score(y_train, poly_pred), 2), \n",
        "           round(precision_score(y_train, poly_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, poly_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, poly_pred,average='macro'), 2)])\n",
        "t.add_row([\"Sigmoid\", round(accuracy_score(y_train, sigmoid_pred), 2), \n",
        "           round(precision_score(y_train, sigmoid_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, sigmoid_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, sigmoid_pred,average='macro'), 2)])\n",
        "t.add_row([\"RBF\", round(accuracy_score(y_train, rbf_pred), 2), \n",
        "           round(precision_score(y_train, rbf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, rbf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, rbf_pred,average='macro'), 2)])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2184cb18-adee-4b72-b4d4-ac1f8072a159"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----------+--------+------+\n",
            "|  Kernel | Accuracy | Precision | Recall |  F1  |\n",
            "+---------+----------+-----------+--------+------+\n",
            "|  Linear |   0.97   |    0.97   |  0.96  | 0.96 |\n",
            "|   Poly  |   0.91   |    0.91   |  0.88  | 0.9  |\n",
            "| Sigmoid |   0.44   |    0.44   |  0.39  | 0.38 |\n",
            "|   RBF   |   0.92   |    0.92   |  0.9   | 0.91 |\n",
            "+---------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = svm.SVC(kernel ='linear')\n",
        "x_train = datasets.load_digits().data\n",
        "y_train = datasets.load_digits().target\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_train)\n",
        "\n",
        "poly = svm.SVC(kernel='poly', degree=5)\n",
        "poly.fit(x_train, y_train)\n",
        "\n",
        "sigmoid = svm.SVC(kernel='sigmoid')\n",
        "sigmoid.fit(x_train, y_train)\n",
        "\n",
        "rbf = svm.SVC(kernel='rbf')\n",
        "rbf.fit(x_train, y_train)\n",
        "\n",
        "poly_pred =poly.predict(x_train)\n",
        "sigmoid_pred = sigmoid.predict(x_train)\n",
        "rbf_pred = rbf.predict(x_train)\n",
        "\n",
        "lr = LogisticRegression(random_state = 0)\n",
        "lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(x_train)\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "tree_pred = tree.predict(x_train)\n",
        "\n",
        "\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(x_train, y_train)\n",
        "kNN_pred = kNN.predict(x_train)\n",
        "\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"Logicstic\", round(accuracy_score(y_train, lr_pred), 2), \n",
        "           round(precision_score(y_train, lr_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, lr_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, lr_pred,average='macro'), 2)])\n",
        "t.add_row([\"Decision Tree\", round(accuracy_score(y_train, tree_pred), 2), \n",
        "           round(precision_score(y_train, tree_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, tree_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, tree_pred,average='macro'), 2)])\n",
        "t.add_row([\"kNN\", round(accuracy_score(y_train, kNN_pred), 2), \n",
        "           round(precision_score(y_train, kNN_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, kNN_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, kNN_pred,average='macro'), 2)])\n",
        "t.add_row([\"Linear\", round(accuracy_score(y_train, y_pred), 2), \n",
        "           round(precision_score(y_train, y_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, y_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, y_pred,average='macro'), 2)])\n",
        "t.add_row([\"Poly\", round(accuracy_score(y_train, poly_pred), 2), \n",
        "           round(precision_score(y_train, poly_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, poly_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, poly_pred,average='macro'), 2)])\n",
        "t.add_row([\"Sigmoid\", round(accuracy_score(y_train, sigmoid_pred), 2), \n",
        "           round(precision_score(y_train, sigmoid_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, sigmoid_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, sigmoid_pred,average='macro'), 2)])\n",
        "t.add_row([\"RBF\", round(accuracy_score(y_train, rbf_pred), 2), \n",
        "           round(precision_score(y_train, rbf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, rbf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, rbf_pred,average='macro'), 2)])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ion3X_apJVZD",
        "outputId": "f19abc91-d559-4420-bd2a-a067ea9ca201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|   Logicstic   |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "| Decision Tree |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "|      kNN      |   0.99   |    0.99   |  0.99  | 0.99 |\n",
            "|     Linear    |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "|      Poly     |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "|    Sigmoid    |   0.9    |    0.9    |  0.9   | 0.9  |\n",
            "|      RBF      |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "credit_cards = pd.read_csv(\"creditcard.csv\")\n",
        "y_train = credit_cards['Class']\n",
        "x_train = credit_cards.iloc[:, :30]\n",
        "model = svm.SVC(kernel ='linear')\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_train)\n",
        "\n",
        "poly = svm.SVC(kernel='poly', degree=5)\n",
        "poly.fit(x_train, y_train)\n",
        "\n",
        "sigmoid = svm.SVC(kernel='sigmoid')\n",
        "sigmoid.fit(x_train, y_train)\n",
        "\n",
        "rbf = svm.SVC(kernel='rbf')\n",
        "rbf.fit(x_train, y_train)\n",
        "\n",
        "poly_pred =poly.predict(x_train)\n",
        "sigmoid_pred = sigmoid.predict(x_train)\n",
        "rbf_pred = rbf.predict(x_train)\n",
        "\n",
        "lr = LogisticRegression(random_state = 0)\n",
        "lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(x_train)\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "tree_pred = tree.predict(x_train)\n",
        "\n",
        "\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(x_train, y_train)\n",
        "kNN_pred = kNN.predict(x_train)\n",
        "\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"Logicstic\", round(accuracy_score(y_train, lr_pred), 2), \n",
        "           round(precision_score(y_train, lr_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, lr_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, lr_pred,average='macro'), 2)])\n",
        "t.add_row([\"Decision Tree\", round(accuracy_score(y_train, tree_pred), 2), \n",
        "           round(precision_score(y_train, tree_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, tree_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, tree_pred,average='macro'), 2)])\n",
        "t.add_row([\"kNN\", round(accuracy_score(y_train, kNN_pred), 2), \n",
        "           round(precision_score(y_train, kNN_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, kNN_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, kNN_pred,average='macro'), 2)])\n",
        "t.add_row([\"Linear\", round(accuracy_score(y_train, y_pred), 2), \n",
        "           round(precision_score(y_train, y_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, y_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, y_pred,average='macro'), 2)])\n",
        "t.add_row([\"Poly\", round(accuracy_score(y_train, poly_pred), 2), \n",
        "           round(precision_score(y_train, poly_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, poly_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, poly_pred,average='macro'), 2)])\n",
        "t.add_row([\"Sigmoid\", round(accuracy_score(y_train, sigmoid_pred), 2), \n",
        "           round(precision_score(y_train, sigmoid_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, sigmoid_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, sigmoid_pred,average='macro'), 2)])\n",
        "t.add_row([\"RBF\", round(accuracy_score(y_train, rbf_pred), 2), \n",
        "           round(precision_score(y_train, rbf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_train, rbf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_train, rbf_pred,average='macro'), 2)])\n",
        "print(t)\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdb1cd1-4e72-45c9-a0ff-5e542517ac0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}